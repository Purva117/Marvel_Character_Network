{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the CSV file\n",
    "file_path = 'marvel_movies_processed.csv'\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Display the first few rows of the dataframe\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display basic information about the dataframe\n",
    "data.info()\n",
    "\n",
    "# Display the first few rows of the dataframe\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Initialize an empty graph\n",
    "G = nx.Graph()\n",
    "\n",
    "# Iterate over each movie to add edges between characters\n",
    "for index, row in data.iterrows():\n",
    "    movie_characters = row['Characters'].split(', ')  # Adjust this split if characters are stored differently\n",
    "    for i, char1 in enumerate(movie_characters):\n",
    "        for char2 in movie_characters[i + 1:]:\n",
    "            if G.has_edge(char1, char2):\n",
    "                G[char1][char2]['weight'] += 1\n",
    "            else:\n",
    "                G.add_edge(char1, char2, weight=1)\n",
    "\n",
    "# Draw the network\n",
    "plt.figure(figsize=(12, 12))\n",
    "pos = nx.spring_layout(G, k=0.3)\n",
    "nx.draw(G, pos, with_labels=True, node_size=50, font_size=10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate centrality measures\n",
    "degree_centrality = nx.degree_centrality(G)\n",
    "betweenness_centrality = nx.betweenness_centrality(G)\n",
    "closeness_centrality = nx.closeness_centrality(G)\n",
    "\n",
    "# Display top 10 characters by degree centrality\n",
    "sorted(degree_centrality.items(), key=lambda x: x[1], reverse=True)[:10]\n",
    "\n",
    "# Community detection using the Girvan-Newman method\n",
    "from networkx.algorithms.community import girvan_newman\n",
    "\n",
    "communities = girvan_newman(G)\n",
    "top_level_communities = next(communities)\n",
    "sorted(map(sorted, top_level_communities))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dataset with network features\n",
    "features = []\n",
    "for node in G.nodes():\n",
    "    features.append([\n",
    "        node,\n",
    "        degree_centrality[node],\n",
    "        betweenness_centrality[node],\n",
    "        closeness_centrality[node],\n",
    "        G.degree(node)\n",
    "    ])\n",
    "\n",
    "# Convert to DataFrame\n",
    "features_df = pd.DataFrame(features, columns=['Character', 'DegreeCentrality', 'BetweennessCentrality', 'ClosenessCentrality', 'Degree'])\n",
    "\n",
    "# Display the features DataFrame\n",
    "print(features_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Visualize the centrality measures\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.barh(features_df['Character'], features_df['DegreeCentrality'])\n",
    "plt.xlabel('Degree Centrality')\n",
    "plt.ylabel('Character')\n",
    "plt.title('Degree Centrality of Marvel Characters')\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.barh(features_df['Character'], features_df['BetweennessCentrality'])\n",
    "plt.xlabel('Betweenness Centrality')\n",
    "plt.ylabel('Character')\n",
    "plt.title('Betweenness Centrality of Marvel Characters')\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.barh(features_df['Character'], features_df['ClosenessCentrality'])\n",
    "plt.xlabel('Closeness Centrality')\n",
    "plt.ylabel('Character')\n",
    "plt.title('Closeness Centrality of Marvel Characters')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyvis.network import Network\n",
    "\n",
    "# Initialize Pyvis network\n",
    "net = Network(notebook=True)\n",
    "\n",
    "# Add nodes and edges to the Pyvis network\n",
    "for node in G.nodes():\n",
    "    net.add_node(node, label=node)\n",
    "\n",
    "for edge in G.edges(data=True):\n",
    "    net.add_edge(edge[0], edge[1], value=edge[2]['weight'])\n",
    "\n",
    "# Display the network\n",
    "net.show('marvel_network.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150, 263)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "import networkx as nx\n",
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "file_path = 'marvel_movies_processed.csv'\n",
    "marvel_data = pd.read_csv(file_path)\n",
    "\n",
    "# Display the first few rows of the dataset\n",
    "marvel_data.head()\n",
    "\n",
    "# Initialize a graph\n",
    "G = nx.Graph()\n",
    "\n",
    "# Add nodes and edges\n",
    "for index, row in marvel_data.iterrows():\n",
    "    movie = row['Movie Name']\n",
    "    characters = row['Characters']\n",
    "    \n",
    "    # Add movie as a node\n",
    "    G.add_node(movie, type='movie')\n",
    "    \n",
    "    # Add characters and connect them to the movie\n",
    "    if isinstance(characters, str):\n",
    "        char_list = [char.strip() for char in characters.split(',')]\n",
    "        for char in char_list:\n",
    "            G.add_node(char, type='character')\n",
    "            G.add_edge(movie, char)\n",
    "\n",
    "# Display the number of nodes and edges\n",
    "num_nodes = G.number_of_nodes()\n",
    "num_edges = G.number_of_edges()\n",
    "\n",
    "num_nodes, num_edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'marvel_network.json'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Prepare data for D3.js\n",
    "nodes = [{'id': node, 'group': 'movie' if data['type'] == 'movie' else 'character'} for node, data in G.nodes(data=True)]\n",
    "links = [{'source': source, 'target': target} for source, target in G.edges()]\n",
    "\n",
    "network_data = {'nodes': nodes, 'links': links}\n",
    "\n",
    "# Save data to a JSON file\n",
    "with open('marvel_network.json', 'w') as f:\n",
    "    json.dump(network_data, f)\n",
    "\n",
    "'marvel_network.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150, 263)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "import networkx as nx\n",
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "file_path = 'marvel_movies_processed.csv'\n",
    "marvel_data = pd.read_csv(file_path)\n",
    "\n",
    "# Display the first few rows of the dataset\n",
    "marvel_data.head()\n",
    "\n",
    "# Initialize a graph\n",
    "G = nx.Graph()\n",
    "\n",
    "# Add nodes and edges\n",
    "for index, row in marvel_data.iterrows():\n",
    "    movie = row['Movie Name']\n",
    "    characters = row['Characters']\n",
    "    \n",
    "    # Add movie as a node\n",
    "    G.add_node(movie, type='movie')\n",
    "    \n",
    "    # Add characters and connect them to the movie\n",
    "    if isinstance(characters, str):\n",
    "        char_list = [char.strip() for char in characters.split(',')]\n",
    "        for char in char_list:\n",
    "            G.add_node(char, type='character')\n",
    "            G.add_edge(movie, char)\n",
    "\n",
    "# Display the number of nodes and edges\n",
    "num_nodes = G.number_of_nodes()\n",
    "num_edges = G.number_of_edges()\n",
    "\n",
    "num_nodes, num_edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'marvel_network_characters.json'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "from collections import defaultdict\n",
    "from itertools import combinations\n",
    "\n",
    "# Initialize dictionaries for nodes and edges\n",
    "nodes = set()\n",
    "edges = defaultdict(int)\n",
    "\n",
    "# Iterate over the dataset to build the nodes and edges\n",
    "for index, row in marvel_data.iterrows():\n",
    "    characters = row['Characters']\n",
    "    if isinstance(characters, str):\n",
    "        char_list = [char.strip() for char in characters.split(',')]\n",
    "        nodes.update(char_list)\n",
    "        for char1, char2 in combinations(char_list, 2):\n",
    "            if char1 != char2:\n",
    "                edges[frozenset([char1, char2])] += 1\n",
    "\n",
    "# Convert nodes to a list of dictionaries\n",
    "node_list = [{'id': char, 'group': 'character'} for char in nodes]\n",
    "\n",
    "# Convert edges to a list of dictionaries\n",
    "edge_list = [{'source': list(edge)[0], 'target': list(edge)[1], 'value': count} for edge, count in edges.items()]\n",
    "\n",
    "network_data = {'nodes': node_list, 'links': edge_list}\n",
    "\n",
    "# Save data to a JSON file\n",
    "with open('marvel_network_characters.json', 'w') as f:\n",
    "    json.dump(network_data, f)\n",
    "\n",
    "'marvel_network_characters.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import json\n",
    "from collections import defaultdict\n",
    "from itertools import combinations\n",
    "\n",
    "# Load the data\n",
    "df = pd.read_csv('marvel_movies_processed.csv')\n",
    "\n",
    "# Initialize dictionaries for nodes and edges\n",
    "nodes = set()\n",
    "edges = defaultdict(int)\n",
    "\n",
    "# Iterate over the dataset to build the nodes and edges\n",
    "for index, row in df.iterrows():\n",
    "    characters = row['Characters']\n",
    "    if isinstance(characters, str):\n",
    "        char_list = [char.strip() for char in characters.split(',')]\n",
    "        nodes.update(char_list)\n",
    "        for char1, char2 in combinations(char_list, 2):\n",
    "            if char1 != char2:\n",
    "                edges[frozenset([char1, char2])] += 1\n",
    "\n",
    "# Convert nodes to a list of dictionaries\n",
    "node_list = [{'id': char, 'group': 'character'} for char in nodes]\n",
    "\n",
    "# Create the graph\n",
    "G = nx.Graph()\n",
    "\n",
    "# Add nodes and edges to the graph\n",
    "for node in node_list:\n",
    "    G.add_node(node['id'])\n",
    "\n",
    "for edge, count in edges.items():\n",
    "    edge_list = list(edge)\n",
    "    G.add_edge(edge_list[0], edge_list[1], weight=count)\n",
    "\n",
    "# Calculate metrics\n",
    "degree_centrality = nx.degree_centrality(G)\n",
    "betweenness_centrality = nx.betweenness_centrality(G)\n",
    "closeness_centrality = nx.closeness_centrality(G)\n",
    "\n",
    "# Add metrics to nodes\n",
    "for node in node_list:\n",
    "    node['degree_centrality'] = degree_centrality[node['id']]\n",
    "    node['betweenness_centrality'] = betweenness_centrality[node['id']]\n",
    "    node['closeness_centrality'] = closeness_centrality[node['id']]\n",
    "\n",
    "# Convert edges to a list of dictionaries\n",
    "edge_list = [{'source': list(edge)[0], 'target': list(edge)[1], 'value': count} for edge, count in edges.items()]\n",
    "\n",
    "network_data = {'nodes': node_list, 'links': edge_list}\n",
    "\n",
    "# Save data to a JSON file\n",
    "with open('marvel_network_with_metrics.json', 'w') as f:\n",
    "    json.dump(network_data, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "# Load the CSV file\n",
    "movies_df = pd.read_csv('marvel_movies_processed.csv')\n",
    "\n",
    "# Load the JSON file\n",
    "with open('marvel_network_with_metrics.json', 'r') as f:\n",
    "    network_data = json.load(f)\n",
    "\n",
    "# Create a dictionary to map characters to their movie appearances\n",
    "character_movies = {}\n",
    "\n",
    "for _, row in movies_df.iterrows():\n",
    "    movie_name = row['Movie Name']\n",
    "    release_date = row['Release Date']\n",
    "    characters = row['Characters'].split(', ')\n",
    "    for character in characters:\n",
    "        if character not in character_movies:\n",
    "            character_movies[character] = []\n",
    "        character_movies[character].append({\n",
    "            'movie_name': movie_name,\n",
    "            'release_date': release_date\n",
    "        })\n",
    "\n",
    "# Enrich the network data with movie appearances\n",
    "for node in network_data['nodes']:\n",
    "    character = node['id']\n",
    "    node['movies'] = character_movies.get(character, [])\n",
    "\n",
    "# Save the enriched JSON data\n",
    "with open('marvel_network_with_metrics_characters.json', 'w') as f:\n",
    "    json.dump(network_data, f, indent=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "# Load the CSV file\n",
    "movies_df = pd.read_csv('marvel_movies_processed.csv')\n",
    "\n",
    "# Load the JSON file\n",
    "with open('marvel_network_with_metrics.json', 'r') as f:\n",
    "    network_data = json.load(f)\n",
    "\n",
    "# Create a dictionary to map characters to their movie appearances\n",
    "character_movies = {}\n",
    "characters_set = set()\n",
    "\n",
    "for _, row in movies_df.iterrows():\n",
    "    movie_name = row['Movie Name']\n",
    "    release_date = row['Release Date']\n",
    "    characters = row['Characters'].split(', ')\n",
    "    characters_set.update(characters)\n",
    "    for character in characters:\n",
    "        if character not in character_movies:\n",
    "            character_movies[character] = []\n",
    "        character_movies[character].append({\n",
    "            'movie_name': movie_name,\n",
    "            'release_date': release_date\n",
    "        })\n",
    "\n",
    "# Create a dataframe to calculate correlations\n",
    "characters_list = list(characters_set)\n",
    "correlation_matrix = pd.DataFrame(0, index=characters_list, columns=characters_list)\n",
    "\n",
    "# Fill the dataframe\n",
    "for _, row in movies_df.iterrows():\n",
    "    characters = row['Characters'].split(', ')\n",
    "    for i in range(len(characters)):\n",
    "        for j in range(i + 1, len(characters)):\n",
    "            correlation_matrix.at[characters[i], characters[j]] += 1\n",
    "            correlation_matrix.at[characters[j], characters[i]] += 1\n",
    "\n",
    "# Calculate the correlation\n",
    "correlation_matrix = correlation_matrix.corr().fillna(0)\n",
    "\n",
    "# Enrich the network data with movie appearances and correlations\n",
    "for node in network_data['nodes']:\n",
    "    character = node['id']\n",
    "    node['movies'] = character_movies.get(character, [])\n",
    "    if character in correlation_matrix.index:\n",
    "        top_correlations = correlation_matrix[character].nlargest(4).index[1:4]\n",
    "        node['top_correlations'] = {\n",
    "            other: correlation_matrix.at[character, other]\n",
    "            for other in top_correlations\n",
    "        }\n",
    "\n",
    "# Save the enriched JSON data\n",
    "with open('marvel_network_with_metrics_correlation.json', 'w') as f:\n",
    "    json.dump(network_data, f, indent=4)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
